{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07A_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "2l-OFjBU_2D6",
        "colab_type": "text"
      },
      "source": [
        "#  CNN (konvolucione neuralne mreže)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jglSyj3pCaKa",
        "colab_type": "text"
      },
      "source": [
        "**\"A class of deep neural networks most commonly applied to analyzing visual imagery\"**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "OFJr40a4_2D8",
        "colab_type": "text"
      },
      "source": [
        "## Pregled\n",
        "* CNN\n",
        "* Slojevi\n",
        "* Novi pogled na protok podataka\n",
        "* Arhitektura\n",
        "* Konvolucija\n",
        "* Pooling\n",
        "* Arhitektura - ponovo\n",
        "* Česti problemi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX67DRtO1EZU",
        "colab_type": "text"
      },
      "source": [
        "## Konvolucione neuralne mreže (ConvNet, CNN)\n",
        "* Tip NN specijalno namenjen slučajevima kada su ulazni podaci slike\n",
        "  * Opštije: kada je umesto feature vektora ulaz predstavljen matricom pri čemu postoje pravilnosti u obe dimenzije\n",
        "* **Kao i MLP**: feedforward mreža, sastoji se od neurona sa aktivacionim funkcijama, može imati raznovrsnu arhitekturu, na isti način se vrši forward propagation, iste su funkcije troška, na isti način se vrši trening (backpropagation od troška po slojevima unazad)\n",
        "* **Za razliku od MLP**: novi tipovi slojeva pogodni za rad sa slikama, novi pogled na protok podataka, standardni šabloni po pitanju arhitekture\n",
        "\n",
        "## Slojevi\n",
        "* U slučaju MLP imali smo samo jedan tip sloja: **potpuno povezan** (Fully Connected, FC, Dense)\n",
        "  * Ovaj sloj je definisan trojkom  $(W, b, f)$ - matrica težina, bias vektor, funkcija aktivacije\n",
        "  * Ulaz (vektor) se množi sa $W$, dodaje $b$ i zatim primenjuje $f$ kako bi se dobio novi vektor\n",
        "* U slučaju CNN uvodimo dva nova, malo drukčija, sloja: **konvoluciju** (Conv) i **pooling** (Pool)\n",
        "* Takođe, aktivacione funkcije možemo zarad jednostavnosti posmatrati kao slojeve za sebe\n",
        "\n",
        "## Novi pogled na protok podataka\n",
        "* CNN svaki međurezultat posmatraju (umesto kao feature vektor) kao 3D tenzor $(W,H,C)$ (širina, visina, broj kanala tj. dubina)\n",
        "* Ulazni podaci su slika tj. 3D tenzor npr. $(W, H, 3)$ u slučaju RGB ili $(W, H, 1)$ u slučaju BW slika\n",
        "* [Ilustracija novog pogleda na protok podataka](http://cs231n.github.io/assets/cnn/cnn.jpeg)\n",
        "  \n",
        "## Arhitektura\n",
        "* Jedna CNN će se sastojati od niza **Conv** i **Pool** slojeva koji transformišu 3D tenzor (tj. sliku) u novi 3D tenzor (tj. novu \"sliku\", iako dobijene \"slike\" brzo prestaju da imaju smisla vizuelno - barem ne na onaj način na koji bismo očekivali)\n",
        "* Na samom kraju ćemo uglavnom imati jedan ili više FC slojeva koji, kao i inače, rade nad vektorskom reprezentacijom\n",
        "* **Dakle**: Conv i Pool transformišu sliku tj. skup feature-a, a finalni FC slojevi (tj. finalni MLP) koristi te feature-e umesto originalnih kao vektor nad kojim vrši predikciju\n",
        "* [Ilustracija arhitekture 1](http://cs231n.github.io/assets/cnn/convnet.jpeg)\n",
        "* [Ilustracija arhitekture 2](https://cdn-images-1.medium.com/max/1600/1*uAeANQIOQPqWZnnuH-VEyw.jpeg)\n",
        "\n",
        "## Konvolucija\n",
        "* **Motivacija**: Primena FC sloja na RGB sliku 200x200 zahteva 120000 težina po neuronu. Ovaj broj je veliki jer svaki neuron \"posmatra\" svaki drugi\n",
        "* Treba nam sloj koji bolje koristi prostorne pravilnosti u slici a ima manje parametara od FC\n",
        "* **Ideja**: Svaki neuron posmatra samo deo ulaza umesto ceo ulaz (sada je jasno zašto se FC zove FC tj. Dense)\n",
        "* Podsetnik: ulaz je 3D tenzor $(W, H, C)$\n",
        "* Konvolucioni sloj se sastoji od niza kernela (filtera)\n",
        "* Jedan kernel je 3D tenzor $(K, K, C)$\n",
        "* Svaki kernel proizvodi jedan kanal izlazne slike ($N_K$ kernela daje izlazni 3D tenzor dimenzija $(W', H', N_K)$, gde se $W'$ i $H'$ mogu lako izračunati)\n",
        "* Sada se fokusirajmo na jedan kernel $(K, K, C)$ i kako on vrši transformaciju $(W,H,C) \\to (W', H')$\n",
        "* Ovde dolazimo do operacije **konvolucije**: prevlačimo kernel preko ulazne slike po širini i dužini (kernel je uvek iste dubine tj. broja kanala kao ulaz) i za svaku poziciju računamo skalarni proizvod vrednosti u ulazu i u kernelu i to upisujemo kao jednu od vrednosti na izlazu\n",
        "* Posmatrajmo za početak slučaj C=1\n",
        "* [Prikaz konvolucije za C=1 i K=3](https://cdn-images-1.medium.com/max/1200/1*1VJDP6qDY9-ExTuQVEOlVg.gif)\n",
        "* [Prikaz konvolucije za C=1 i K=5](https://cdn-images-1.medium.com/max/1200/1*nYf_cUIHFEWU1JXGwnz-Ig.gif)\n",
        "* [Prikaz konvolucije sa konkretnim vrednostima za C=1 i K=3](https://cdn-images-1.medium.com/max/1200/1*uoWYsCV5vBU8SHFPAPao-w.gif)\n",
        "* Animacija na [cs231n beleškama za CNN](http://cs231n.github.io/convolutional-networks/) najbolje ilustruje konvolucioni sloj i prikazuje slučja kada imamo više kanala i više kernela\n",
        "* Sada kada smo razumeli konvoluciju možemo pokušati da je posmatramo na način na koji smo definisali MLP: koristeći pojam neurona\n",
        "  * U kontekstu neurona jedan kernel se može posmatrati kao $W' * H'$ neurona pri čemu svaki ima svoje **receptivno polje** (dakle nije \"dense\")\n",
        "  * Svi neuroni (po dubini) koji su na istoj poziciji u okviru kernela imaju isto receptivno polje\n",
        "  * Svi neuroni koji su deo istog kernela dele težine\n",
        "  * Ako su bitne horizontalne ivice, bitne su svuda u okviru slike, pa ima smisla da koristimo iste težine za različita receptivna polja\n",
        "  * Deljenje težina dovodi do bolje efikasnosti Conv slojeva\n",
        "  * [Prikaz pogleda na CNN u kontekstu neurona](http://cs231n.github.io/assets/cnn/depthcol.jpeg)\n",
        "* **Parametri Conv sloja**: broj kernela, veličina kernela, stride, padding (isti za jedan Conv sloj)\n",
        "* **Rezultat**: jednostavni feature-i na nižim, a kompleksniji na višim slojevima\n",
        "\n",
        "## Pooling\n",
        "- Za razliku od Conv, Pool je dosta jednostavniji sloj **bez learnable parametara** \n",
        "- Ima dva fiksna parametra, dimenziju i stride\n",
        "- Služi da smanji $W$ i $H$ (pritom ne menja broj kanala)\n",
        "- Svaki Pool sloj deli ulaznu sliku (po širini i dužini) na kvadrate fiksne veličine (često 2 ili 3) i \"sumira\" ih nekom funkcijom (max, min, avg)\n",
        "- [Ilustracija](http://cs231n.github.io/assets/cnn/pool.jpeg)\n",
        "\n",
        "## Arhitektura - ponovo\n",
        "- Najčešće se koristi arhitektura nalik sledećoj:\n",
        "\n",
        "```\n",
        " [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC\n",
        "```\n",
        "- **ILSVRC**: takmičenje u klasifikaciji slika na ImageNet skupu (1000 kategorija, 1.2M slika)\n",
        "  - Često se koristi kao merilo \"najbolje\" konvolucione mreže\n",
        "  - **Skorašnji pobednici**: AlexNet, LeNet, GoogLeNet, VGGNet, ResNet\n",
        "- **Transfer learning**: mrežu treniranu za jedan zadatak primenjujemo na drugi\n",
        "  - Tako možemo konvolucioni deo ResNet-a pretreniranog na ImageNet (koji sami ne bismo nikad uspeli da istreniramo) da primenimo na bilo koji problem kao feature extraction korak (i samo dodamo MLP na kraj koji \"dotreniramo\" za konkretan zadatak\n",
        "\n",
        "## Česti problemi\n",
        "- [Odličan pregled aktuelnih problema i radova - na dnu članka](https://skymind.ai/wiki/convolutional-network)\n",
        "\n",
        "## Resursi\n",
        "- [cs231n: Detaljan uvod u CNN, dobro za razvijanje intuicije](http://cs231n.github.io/convolutional-networks/)\n",
        "- [Kraći uvod, dobre animacije](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdNxeeJ98sYr",
        "colab_type": "text"
      },
      "source": [
        "## Implementacija CNN u Keras\n",
        "* U TF bi takođe bilo relativno jednostavno (`tf.layers.conv2d` i `tf.layers.max_pooling2d`) ali sada nema razloga da ne koristimo Keras (fokus je na višem nivou)\n",
        "* Skup [CIFAR-10](https://skymind.ai/wiki/convolutional-network) za klasifikaciju slika (\"lakša verzija ImageNet\")\n",
        "* 60000 32x32 RGB slika u 10 klasa (svaka klasa ima jednako slika), 5/6 toga je trening test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtyMBv8s8vCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Treniramo jednostavan duboki CNN na CIFAR10\n",
        "Dobijamo 75% accuracy na validacionom skupu za 25 epoha, što nije ni blizu \n",
        "dovoljno tj. mreža bi nastavila da uči i nakon toga, a trening već traje dugo\n",
        "'''\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "# Parametri\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "num_predictions = 20\n",
        "\n",
        "# Vrsimo \"data augmentation\": prosirujemo skup podataka jednostavnim metodama\n",
        "# obrade slike kako bismo dobili vise materijala za treniranje\n",
        "data_augmentation = True\n",
        "\n",
        "# Ucitavamo CIFAR10 trening i test podatke\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "\n",
        "# Kreiramo one-hot vektore\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Kreiramo model\n",
        "# Prvi sloj je Conv sloj sa 32 kernela 3x3 i 'same' strategijom paddinga\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # Max pooling 2x2\n",
        "model.add(Dropout(rate=0.75))  # Dropout metoda regularizacije\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.75))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))  # Prvi potpuno povezan sloj\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(num_classes))  # Finalni potpuno povezan sloj\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Koristimo RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Kompilacija modela\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Normalizacija podataka\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    # Prosto treniranje modela bez augmentacije\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # Preprocesiranje augmentovanih podataka\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Neke vrednosti potrebne za augmentaciju podataka je neophodno fitovati\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fitujemo model na augmentovanim podacima sa 4 workera\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                        workers=4)\n",
        "\n",
        "# Ispisujemo finalni rezultat na test skupu\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}