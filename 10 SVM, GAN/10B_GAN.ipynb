{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10B_GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "2l-OFjBU_2D6",
        "colab_type": "text"
      },
      "source": [
        "#  Generative Adversarial Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jglSyj3pCaKa",
        "colab_type": "text"
      },
      "source": [
        "**\"Deep neural net architectures comprised of two nets, pitting one against the other\"**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "OFJr40a4_2D8",
        "colab_type": "text"
      },
      "source": [
        "## Pregled\n",
        "* GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUoxHIC2TT-M",
        "colab_type": "text"
      },
      "source": [
        "## GAN\n",
        "- Jedna od najinovativnijih i najpopularnijih novih ideja u ML u poslednjih 10 godina\n",
        "- Generativni model\n",
        "- Svakim danom sve više radova https://imgur.com/IFXxquc\n",
        "- I dalje ne znamo baš kako funkcioniše\n",
        "- Dve mreže koje se \"bore\": generator i diskriminator\n",
        "- Treniramo ih naizmenično u isto vreme, nemamo fiksnu funkciju troška\n",
        "- Vrlo se teško treniraju i lako divergiraju\n",
        "\n",
        "## Struktura\n",
        "- \"Prevarant\" i \"policajac\": prevarant uči sve bolje da pravi lažne novčanice, policajac uči sve bolje da ih razlikuje\n",
        "  - Rezultat: prevarant postane jako dobar\n",
        "- Dakle, generator treba da generiše primere takve da diskriminator ne može da ih razlikuje od pravih\n",
        "- Trening režim: https://imgur.com/807GTFL\n",
        "- Generator menja svoje težine tako da dobije što veći skor od diskriminatora\n",
        "- Diskriminator menja svoje težine tako da da što manji skor generatoru ali što veći skor realnim primerima\n",
        "- Funkcija troška je mreža!\n",
        "-Trik: treba paziti da diskriminator ne ode previše ispred generatora, ne treniramo ga do konvergencije\n",
        "  - Ovaj i još mnogo trikova\n",
        "  - WGAN, DCGAN, ...\n",
        "\n",
        "- Istorija ML: \n",
        "  - Feature engineering pre modela\n",
        "  - Neuralne mreže (nema potrebe za feature engineeringom ali nam treba cost funkcija)\n",
        "  - GAN (nema potrebe za cost funkcijom ali moramo da znamo kako da radimo optimizaciju)\n",
        "  - ??? (learning to learn)\n",
        "  \n",
        "## Rezultati\n",
        "- Aritmetika u latentnom prostoru\n",
        "- Interpolacija između slika\n",
        "- SuperResolution\n",
        "- Interaktivni GAN\n",
        "- Style transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCOcEi7hYkF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist=input_data.read_data_sets(\"MNIST_data\")\n",
        "\n",
        "def generator(z,reuse=None):\n",
        "    with tf.variable_scope('gen',reuse=reuse):\n",
        "        hidden1=tf.layers.dense(inputs=z,units=128,activation=tf.nn.leaky_relu)\n",
        "        hidden2=tf.layers.dense(inputs=hidden1,units=128,activation=tf.nn.leaky_relu)\n",
        "        output=tf.layers.dense(inputs=hidden2,units=784,activation=tf.nn.tanh)\n",
        "        \n",
        "        return output\n",
        "    \n",
        "def discriminator(X,reuse=None):\n",
        "    with tf.variable_scope('dis',reuse=reuse):\n",
        "        hidden1=tf.layers.dense(inputs=X,units=128,activation=tf.nn.leaky_relu)\n",
        "        hidden2=tf.layers.dense(inputs=hidden1,units=128,activation=tf.nn.leaky_relu)\n",
        "        logits=tf.layers.dense(hidden2,units=1)\n",
        "        output=tf.sigmoid(logits)\n",
        "        \n",
        "        return output,logits\n",
        "    \n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "real_images=tf.placeholder(tf.float32,shape=[None,784])\n",
        "z=tf.placeholder(tf.float32,shape=[None,100])\n",
        "\n",
        "G=generator(z)\n",
        "D_output_real,D_logits_real=discriminator(real_images)\n",
        "D_output_fake,D_logits_fake=discriminator(G,reuse=True)\n",
        "\n",
        "def loss_func(logits_in,labels_in):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))\n",
        "\n",
        "D_real_loss=loss_func(D_logits_real,tf.ones_like(D_logits_real)*0.9) #Smoothing for generalization\n",
        "D_fake_loss=loss_func(D_logits_fake,tf.zeros_like(D_logits_real))\n",
        "D_loss=D_real_loss+D_fake_loss\n",
        "\n",
        "G_loss= loss_func(D_logits_fake,tf.ones_like(D_logits_fake))\n",
        "\n",
        "lr=0.001\n",
        "\n",
        "#Do this when multiple networks interact with each other\n",
        "tvars=tf.trainable_variables()  #returns all variables created(the two variable scopes) and makes trainable true\n",
        "d_vars=[var for var in tvars if 'dis' in var.name]\n",
        "g_vars=[var for var in tvars if 'gen' in var.name]\n",
        "\n",
        "D_trainer=tf.train.AdamOptimizer(lr).minimize(D_loss,var_list=d_vars)\n",
        "G_trainer=tf.train.AdamOptimizer(lr).minimize(G_loss,var_list=g_vars)\n",
        "\n",
        "batch_size=100\n",
        "epochs=100\n",
        "init=tf.global_variables_initializer()\n",
        "\n",
        "samples=[] #generator examples\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(epochs):\n",
        "        num_batches=mnist.train.num_examples//batch_size\n",
        "        for i in range(num_batches):\n",
        "            batch=mnist.train.next_batch(batch_size)\n",
        "            batch_images=batch[0].reshape((batch_size,784))\n",
        "            batch_images=batch_images*2-1\n",
        "            batch_z=np.random.uniform(-1,1,size=(batch_size,100))\n",
        "            _=sess.run(D_trainer,feed_dict={real_images:batch_images,z:batch_z})\n",
        "            _=sess.run(G_trainer,feed_dict={z:batch_z})\n",
        "            \n",
        "        print(\"on epoch{}\".format(epoch))\n",
        "        \n",
        "        sample_z=np.random.uniform(-1,1,size=(1,100))\n",
        "        gen_sample=sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
        "        \n",
        "        samples.append(gen_sample)\n",
        "\n",
        "plt.imshow(samples[0].reshape(28,28))\n",
        "\n",
        "plt.imshow(samples[99].reshape(28,28))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX67DRtO1EZU",
        "colab_type": "text"
      },
      "source": [
        "## Resursi\n",
        "[Primene](https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900)\n"
      ]
    }
  ]
}